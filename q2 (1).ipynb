{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a802df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c433b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Humor,Hist,Media,Food/'    #insert file path\n",
    "docs = []\n",
    "data = \"\"\n",
    "files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e53cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in os.listdir(path):\n",
    "    p = path + file\n",
    "    files.append(file)\n",
    "    f = open(p,\"r\",encoding = \"latin-1\")\n",
    "    d = f.read()\n",
    "    docs.append(d)\n",
    "    data = data + d\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a132b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.lower() #convert text to lower case\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9517110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(data) # word tokenizer\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_removed = [w for w in tokens if not w in stopwords.words()]  #removing stopwords\n",
    "#stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \" \".join(stopwords_removed)\n",
    "res = re.sub(r'[^\\w\\s]', '', data) #removing punctuation\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51be189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(res)\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c20952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2(b) \n",
    "def process(s):\n",
    "    lower_text = s.lower()\n",
    "    #print(lower_text)\n",
    "    tokenize = nltk.word_tokenize(lower_text)\n",
    "    #print(tokenize)\n",
    "    stopwords_removed = [w for w in tokenize if not w in stopwords.words()]\n",
    "    data = \" \".join(stopwords_removed)\n",
    "    res = re.sub(r'[^\\w\\s]', '', data)\n",
    "    \n",
    "    return nltk.word_tokenize(res)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "positonal_index = {}\n",
    "doc_id = 1\n",
    "\n",
    "for doc in docs:\n",
    "    processed_data = process(doc)\n",
    "\n",
    "    \n",
    "    for index, term in enumerate(processed_data):\n",
    "        \n",
    "        if term in positonal_index:\n",
    "            \n",
    "            positonal_index[term][0] = positonal_index[term][0] + 1\n",
    "            \n",
    "            if doc_id in positonal_index[term][1]:\n",
    "                positonal_index[term][1][doc_id].append(index)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                positonal_index[term][1][doc_id] = [index]\n",
    "        \n",
    "        else:\n",
    "            positonal_index[term] = []\n",
    "            positonal_index[term].append(1)\n",
    "            positonal_index[term].append({})\n",
    "            positonal_index[term][1][doc_id] = [index]\n",
    "        \n",
    "    \n",
    "    doc_id = doc_id + 1\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd7beb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positonal_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd8b845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You mean funny names\n",
      "['mean', 'funny', 'names']\n"
     ]
    }
   ],
   "source": [
    "phase_query = input()\n",
    "#pre process phase query\n",
    "#updated_query\n",
    "updated_query = process(phase_query)\n",
    "print(updated_query)\n",
    "\n",
    "indexing = []\n",
    "\n",
    "for q in updated_query:\n",
    "    k = positonal_index.get(q)\n",
    "    if(k != None):\n",
    "        indexing.append(k)\n",
    "\n",
    "#indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "199f2e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': {3: [55, 129]}, 'funny': {3: [56], 5: [143]}, 'names': {3: [35, 45, 53, 57, 60, 61, 119]}}\n"
     ]
    }
   ],
   "source": [
    "mp = {}\n",
    "\n",
    "for i in updated_query:\n",
    "    #print(i)\n",
    "    if(positonal_index.get(i) != None):\n",
    "        #print(positonal_index.get(i)[1])\n",
    "        mp[i] = positonal_index.get(i)[1]\n",
    "        \n",
    "print(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55070e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for query\n",
      "Document number is : 3\n",
      "Updated Query : mean funny names\n",
      "\n",
      "Number of docs retrieved\n",
      "2\n",
      "\n",
      "Name of docs retrieved\n",
      "abbott.txt\n",
      "a_fish_c.apo\n"
     ]
    }
   ],
   "source": [
    "doc_id = []\n",
    "path = {}\n",
    "#print(len(updated_query))\n",
    "\n",
    "if((len(updated_query) > 0 and len(indexing)==0) or len(updated_query) ==0):\n",
    "    print(\"No such document\")\n",
    "\n",
    "else:\n",
    "    if(len(updated_query)==1):\n",
    "        print(\"Doc for the given phase query is/are :\")\n",
    "        for key,term in indexing[0][1].items():\n",
    "            print(key)\n",
    "    \n",
    "    else:\n",
    "        print(\"Searching for query\")\n",
    "        match_docs = []\n",
    "        for i in range(1068):\n",
    "            op = 0\n",
    "            \n",
    "            \n",
    "            for j in updated_query:\n",
    "                if i in mp[j]:\n",
    "                    op = op+1\n",
    "                \n",
    "            \n",
    "            if(op == len(updated_query)):\n",
    "                match_docs.append(i)\n",
    "                \n",
    "        for i in match_docs:\n",
    "            if(len(updated_query)==2):\n",
    "                arr1 = mp[updated_query[0]][i]\n",
    "                arr2 = mp[updated_query[1]][i]\n",
    "                done=0\n",
    "                \n",
    "                for doc in arr1:\n",
    "                    for doc2 in arr2:\n",
    "                        if(doc+1==doc2):\n",
    "                            done=1\n",
    "                            print(i)\n",
    "                            print(updated_query[0] + \" \" + updated_query[1])\n",
    "                            break\n",
    "                        if done==1:\n",
    "                           break\n",
    "            \n",
    "            \n",
    "            if(len(updated_query)==3):\n",
    "                arr1 = mp[updated_query[0]][i]\n",
    "                arr2 = mp[updated_query[1]][i]\n",
    "                arr3 = mp[updated_query[2]][i]\n",
    "                #print(arr1)\n",
    "                #print(arr2)\n",
    "                #print(arr3)\n",
    "                done=0\n",
    "                \n",
    "                for doc in arr1:\n",
    "                    for doc2 in arr2:\n",
    "                        for doc3 in arr3:\n",
    "                            if(doc+1==doc2 and doc2+1==doc3):\n",
    "                                done=1\n",
    "                                print(\"Document number is : \",end = \"\")\n",
    "                                print(i)\n",
    "                                print(\"Updated Query : \",end = \"\")\n",
    "                                print(updated_query[0] + \" \" + updated_query[1] + \" \" + updated_query[2])\n",
    "                                break\n",
    "                        if done==1:\n",
    "                            break\n",
    "                            \n",
    "            \n",
    "            if(len(updated_query)==4):\n",
    "                arr1 = mp[updated_query[0]][i]\n",
    "                arr2 = mp[updated_query[1]][i]\n",
    "                arr3 = mp[updated_query[2]][i]\n",
    "                arr4 = mp[updated_query[3]][i]\n",
    "                done=0\n",
    "                \n",
    "                for doc in arr1:\n",
    "                    for doc2 in arr2:\n",
    "                        for doc3 in arr3:\n",
    "                            for doc4 in arr4:\n",
    "                                if(doc+1==doc2 and doc2+1==doc3 and doc3+1==doc4):\n",
    "                                    print(\"Document number is : \")\n",
    "                                    done=1\n",
    "                                    print(i)\n",
    "                                    print(\"Query: \",end = \"\")\n",
    "                                    print(updated_query[0] + \" \" + updated_query[1] + \" \" + updated_query[2] + \" \" + updated_query[3])\n",
    "                                    break\n",
    "                            if done==1:\n",
    "                                break\n",
    "                            \n",
    "            \n",
    "            if(len(updated_query)==5):\n",
    "                arr1 = mp[updated_query[0]][i]\n",
    "                arr2 = mp[updated_query[1]][i]\n",
    "                arr3 = mp[updated_query[2]][i]\n",
    "                arr4 = mp[updated_query[3]][i]\n",
    "                arr5 = mp[updated_query[4]][i]\n",
    "                done=0\n",
    "                \n",
    "                for doc in arr1:\n",
    "                    for doc2 in arr2:\n",
    "                        for doc3 in arr3:\n",
    "                            for doc4 in arr4:\n",
    "                                for doc5 in arr5:\n",
    "                                    if(doc+1==doc2 and doc2+1==doc3 and doc3+1==doc4 and doc4+1==doc5):\n",
    "                                        done=1\n",
    "                                        print(\"Document number is :\")\n",
    "                                        print(i)\n",
    "                                        print(\"Query is :\")\n",
    "                                        print(updated_query[0] + \" \" + updated_query[1] + \" \" + updated_query[2] + \" \" + updated_query[3] + \" \" + updated_query[4])\n",
    "                                        break\n",
    "                                if done==1:\n",
    "                                    break\n",
    "               \n",
    "            \n",
    "        #print(match_docs)\n",
    "        \n",
    "        \n",
    "        \n",
    "docs_retrieved = []\n",
    "print()\n",
    "for i in indexing:\n",
    "    \n",
    "    for key,term in i[1].items():\n",
    "        \n",
    "        if key not in docs_retrieved:\n",
    "            docs_retrieved.append(key)\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "print(\"Number of docs retrieved\")        \n",
    "print(len(docs_retrieved))   #number of docs retrieved\n",
    "print()\n",
    "\n",
    "print(\"Name of docs retrieved\")\n",
    "for docs in docs_retrieved:\n",
    "    print(files[docs-1]) #name of docs retrieved\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b38c15",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
